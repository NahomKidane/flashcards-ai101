/**
 * AI Ethics Flashcard Data
 */
const allFlashcards = [
    // AI Ethics Foundations & HCD
    { topic: 'AI Ethics Foundations & HCD', question: 'Name the four core ethical pillars of responsible AI development often referred to as FATP.', answer: 'Fairness, Accountability, Transparency, and Privacy.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Define the ethical pillar of Fairness in the context of AI systems.', answer: 'Ensuring AI systems treat all individuals and groups equitably without systematic disadvantages.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Which ethical pillar focuses on establishing clear responsibility for AI outcomes and providing recourse for affected parties?', answer: 'Accountability.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Define the ethical pillar of Transparency in AI decision-making.', answer: 'Making AI processes understandable and visible to relevant stakeholders.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'The ethical pillar of _____ involves protecting personal data and respecting the boundaries of data collection.', answer: 'Privacy.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'What is the primary goal of Human-Centered Design (HCD) in AI development?', answer: 'Building systems that serve human needs, respect autonomy, and enhance human capabilities.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Describe HCD Step 5, \'Enable User Agency\'.', answer: 'Allowing users to challenge decisions, provide overrides, and offer meaningful opt-out options.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'What is the purpose of forming \'red teams\' in HCD Step 6?', answer: 'To actively identify vulnerabilities and safety issues within the AI system.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'In the Six-Step Guide, what is the final step to ensure ongoing ethical operation?', answer: 'Build in Safety Measures.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Term: Automation', answer: 'Definition: When a machine or software performs a task with minimal to no user intervention.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Term: Augmentation', answer: 'Definition: When a machine or software amplifies a user\'s capabilities to discover new insights collaboratively.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'What defines \'Dual Potential\' in AI technology?', answer: 'The same technology can help or harm communities depending on design and implementation choices.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'As the outcome of an AI-driven task becomes more consequential, what requirement should increase to prevent bias?', answer: 'Human oversight' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Why is human judgment essential even in highly automated AI systems?', answer: 'To mitigate negative impacts arising from automation complacency or bias.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'How does inclusive design address the potential for AI performance differences across cultures?', answer: 'By ensuring equitable outcomes for users of all diverse identities and contexts.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'What tool is commonly used to document AI systems and increase transparency?', answer: 'Model Cards.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Define \'Recourse\' as it relates to the pillar of Accountability.', answer: 'The ability for affected parties to challenge an AI\'s decision or receive a remedy for harm.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'Identify the HCD principle that prioritizes understanding human contexts before determining if AI is appropriate.', answer: 'People-First Approach.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'The HCD principle of _____ involves engaging stakeholders from different backgrounds, especially those affected by the system.', answer: 'Diverse Perspectives.' },
    { topic: 'AI Ethics Foundations & HCD', question: 'What characterizes the HCD principle of Proactive Ethics?', answer: 'Considering ethical implications from the earliest design phases rather than as an afterthought.' },

    // AI Bias Fundamentals
    { topic: 'AI Bias Fundamentals', question: 'Define \'Bias\' in the context of Artificial Intelligence.', answer: 'Systematic errors that create unfair outcomes for particular groups of people.' },
    { topic: 'AI Bias Fundamentals', question: 'Define \'Historical Bias\' in AI systems.', answer: 'Bias occurring when training data reflects past inequalities and discrimination.' },
    { topic: 'AI Bias Fundamentals', question: 'Which bias type is most likely to be introduced during the \'data generation\' stage?', answer: 'Historical Bias.' },
    { topic: 'AI Bias Fundamentals', question: 'Define \'Representation Bias\' in AI.', answer: 'Bias occurring when training data does not adequately represent all groups in the population.' },
    { topic: 'AI Bias Fundamentals', question: 'Which bias type is most likely to be introduced during the \'population selection\' stage?', answer: 'Representation Bias.' },
    { topic: 'AI Bias Fundamentals', question: 'Define \'Harms of Allocation\' in the context of AI systems.', answer: 'When AI systems withhold a good or service from certain groups unfairly.' },
    { topic: 'AI Bias Fundamentals', question: 'The 2019 Apple Card controversy, where men received higher credit limits than women with equal qualifications, is an example of what type of harm?', answer: 'Harms of Allocation' },
    { topic: 'AI Bias Fundamentals', question: 'Define \'Harms of Representation\' in the context of AI systems.', answer: 'When AI systems reinforce negative stereotypes about certain groups.' },
    { topic: 'AI Bias Fundamentals', question: 'Varying accuracy rates in facial recognition algorithms across racial groups and genders is an example of _____.', answer: 'Harms of Representation' },
    { topic: 'AI Bias Fundamentals', question: 'Which psychological phenomenon causes users to place excessive trust in an AI support mechanism?', answer: 'Automation Bias' },
    { topic: 'AI Bias Fundamentals', question: 'What occurs during \'Automation Complacency\'?', answer: 'Users fail to monitor automated processes because they believe the output is consistently reliable.' },
    { topic: 'AI Bias Fundamentals', question: 'True or False: Human-centered AI design focuses on replacing human capabilities with AI.', answer: 'False.' },
    { topic: 'AI Bias Fundamentals', question: 'Explain the concept of \'Garbage In, Garbage Out\' regarding AI training data.', answer: 'If an AI is trained on negative or harmful conversations, it will likely produce similar negative outputs.' },
    { topic: 'AI Bias Fundamentals', question: 'How does AI bias differ from human bias in terms of detection?', answer: 'AI bias can be hidden in complex data and algorithms, making it much harder to detect than human bias.' },
    { topic: 'AI Bias Fundamentals', question: 'True or False: AI systems can create new biases even if they aren\'t present in the initial data.', answer: 'True.' },

    // Bias in Machine Learning Pipelines
    { topic: 'Bias in Machine Learning Pipelines', question: 'List the three main stages of the AI lifecycle where bias can emerge.', answer: 'Data collection/preparation, model design/training, and system deployment/usage.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Define \'Measurement Bias\' in AI systems.', answer: 'Bias occurring when data is not accurately or fairly measured, leading to results that misrepresent reality.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'In AI ethics, what is a \'proxy\' variable?', answer: 'An easier-to-measure substitute for a more representative but harder-to-measure variable.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'In \'Group Unaware\' fairness, why is the \'Zip Code\' variable often problematic?', answer: 'It acts as a strong proxy variable for race in racially segregated areas.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Define \'Aggregation Bias\'.', answer: 'Bias occurring when data from different groups are combined in a way that assumes a single model works equally for all.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Identify the bias type: A medical AI trained on a general population fails to account for specific symptoms in a subgroup.', answer: 'Aggregation Bias.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Which bias type is most likely to be introduced during the \'model definition\' stage?', answer: 'Aggregation Bias.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Define \'Evaluation Bias\'.', answer: 'Bias occurring when the criteria used to assess a model do not fit the actual population the tool is intended to help.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Why are standard benchmarks sometimes insufficient for evaluating AI systems?', answer: 'They may emphasize average performance while overlooking disparities across demographic subgroups.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Identify the bias type: A chatbot passes accuracy tests in a lab but fails when exposed to internet slang and typos.', answer: 'Evaluation Bias.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Define \'Deployment Bias\'.', answer: 'Bias occurring when a system is used in a real-world context that differs from its design or evaluation context.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Which bias type is most likely to be introduced during the \'post-process/integration\' stage?', answer: 'Deployment Bias.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'What is the primary danger of a \'feedback loop\' in representation bias?', answer: 'Poor service for underrepresented groups leads to even less data being collected from them over time.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Contrast Historical Bias and Representation Bias regarding how they are addressed.', answer: 'Representation bias can often be fixed by collecting more diverse data, while historical bias reflects deeper societal problems.' },
    { topic: 'Bias in Machine Learning Pipelines', question: 'Why is it important to disaggregate metrics during AI evaluation?', answer: 'To ensure performance disparities across demographic groups are not hidden by a high overall average.' },

    // Fairness Metrics & Formulas
    { topic: 'Fairness Metrics & Formulas', question: 'What tool serves as the baseline for calculating group fairness metrics by showing correct and incorrect predictions?', answer: 'Confusion Matrix' },
    { topic: 'Fairness Metrics & Formulas', question: 'In a confusion matrix, what is a \'False Positive\' (Type I error)?', answer: 'When the model incorrectly predicts a positive outcome (e.g., marking legitimate email as spam).' },
    { topic: 'Fairness Metrics & Formulas', question: 'In a confusion matrix, what is a \'False Negative\' (Type II error)?', answer: 'When the model incorrectly predicts a negative outcome (e.g., missing an actual spam email).' },
    { topic: 'Fairness Metrics & Formulas', question: 'In the confusion matrix, which value represents \'Legitimate email correctly identified\'?', answer: 'True Negative (TN)' },
    { topic: 'Fairness Metrics & Formulas', question: 'What is the formula for calculating Accuracy in a confusion matrix?', answer: '$\\frac{TP + TN}{TP + TN + FP + FN}$' },
    { topic: 'Fairness Metrics & Formulas', question: 'Which metric answers the question: \'Of all items flagged as positive, how many were actually positive?\'', answer: 'Precision' },
    { topic: 'Fairness Metrics & Formulas', question: 'What is the formula for Precision?', answer: '$\\frac{TP}{TP + FP}$' },
    { topic: 'Fairness Metrics & Formulas', question: 'Which metric answers the question: \'Of all actual positive cases, how many did the model correctly catch?\'', answer: 'Recall (or True Positive Rate)' },
    { topic: 'Fairness Metrics & Formulas', question: 'What is the formula for the True Positive Rate (TPR)?', answer: '$\\frac{TP}{TP + FN}$' },
    { topic: 'Fairness Metrics & Formulas', question: 'What is the formula for the False Positive Rate (FPR)?', answer: '$\\frac{FP}{FP + TN}$' },
    { topic: 'Fairness Metrics & Formulas', question: 'In an email filter with $50$ spam and $50$ legitimate emails, if the model identifies $40$ spam correctly and $45$ legitimate correctly, what is its overall accuracy?', answer: '$85\\%$' },
    { topic: 'Fairness Metrics & Formulas', question: 'A model that classifies $10\\%$ of legitimate emails as spam has a _____ of $10\\%$.', answer: 'False Positive Rate' },

    // Fairness Criteria & Trade-offs
    { topic: 'Fairness Criteria & Trade-offs', question: 'Which type of fairness evaluates if a model performs equally well across different subgroups of a population?', answer: 'Group Fairness' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'Concept: Individual Fairness', answer: 'Definition: A model predicts positive outcomes at the same rate for individuals with similar features.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'Which fairness type tests \'what-if\' scenarios by changing only the sensitive attribute of a record?', answer: 'Counterfactual Fairness' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'Which fairness criterion requires the proportion of individuals receiving a positive outcome to be equal across groups?', answer: 'Demographic Parity (or Statistical Parity)' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'Which fairness criterion ensures that qualified individuals have an equal True Positive Rate regardless of their group?', answer: 'Equal Opportunity' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'If a loan model is $98\\%$ accurate for all demographic groups, it is satisfying the _____ criterion.', answer: 'Equal Accuracy' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'What is the \'Group Unaware\' approach to fairness?', answer: 'Removing protected attributes like race, gender, or age from the dataset entirely.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'What is the central claim of the \'Impossibility Theorem of Machine Fairness\'?', answer: 'It is impossible to optimize a model for more than one type of group fairness simultaneously.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'In the medical risk assessment case study, why is \'Equal Opportunity\' the prioritized fairness metric?', answer: 'It ensures that patients who need care have an equal chance of being identified, minimizing life-threatening false negatives.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'Why might a bank choose \'Equal Accuracy\' for a loan approval model?', answer: 'It balances false positives and false negatives to value overall decision quality and financial safety.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'If a nonprofit selects $50$ men and $50$ women from a pool that is $50\\%$ male and $50\\%$ female, which metric is met?', answer: 'Demographic Parity' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'True or False: A confusion matrix can be used to detect \'Group Unaware\' fairness.', answer: 'False (it is about input data, not model outcomes).' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'What is the recommended approach for teams when perfect fairness metrics are unachievable?', answer: 'Aim for approximate goals close to the target, such as $48-53\\%$ instead of exactly $50\\%$.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'Which fairness metric is most closely linked to existing regulations on financial institutions?', answer: 'Group Fairness' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'What is the first step in the Six-Step Guide to Human-Centered AI Design?', answer: 'Understand People\'s Needs.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'What is the key question asked during HCD Step 2, \'Evaluate AI Appropriateness\'?', answer: 'Whether AI is truly better than non-AI solutions or simpler alternatives.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'What is the primary objective of HCD Step 3, \'Balance Harms vs. Benefits\'?', answer: 'Identifying potential negative outcomes across diverse groups and weighing short and long-term consequences.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'In HCD Step 4, why should developers prototype non-AI solutions first?', answer: 'To test assumptions, validate problem understanding, and generate early feedback without the complexity of AI.' },
    { topic: 'Fairness Criteria & Trade-offs', question: 'When evaluating AI\'s value, what should developers consider if the potential harms likely outweigh the benefits?', answer: 'They should make the responsible decision not to build the system.' },
];
